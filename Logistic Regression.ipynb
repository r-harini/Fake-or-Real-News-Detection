{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=pd.read_csv(\"True.csv\")\n",
    "fake=pd.read_csv(\"Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "true['label']='True'\n",
    "fake['label']='Fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([true,fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the string\n",
    "def clean_str(string):\n",
    "    string = re.sub(r'http\\S+', 'link', string) # replace links by generic text link\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "\n",
    "    cleanr = re.compile('<.*?>')\n",
    "\n",
    "    string = re.sub(r'\\d+', '', string)\n",
    "    string = re.sub(cleanr, '', string)\n",
    "    string = re.sub(\"'\", '', string)\n",
    "    string = re.sub(r'\\W+', ' ', string)\n",
    "    string = string.replace('_', '')\n",
    "\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(word_list):\n",
    "    no_stop_words=[w for w in word_list if not w in stop_words]\n",
    "    return no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44898\n",
      "44898\n"
     ]
    }
   ],
   "source": [
    "sentences=[]\n",
    "text=df.text\n",
    "labels=[]\n",
    "for row in text:\n",
    "    #print(row)\n",
    "    row=clean_str(row)\n",
    "    #print(row)\n",
    "    wo_stop=remove_stopwords(row.split(\" \"))\n",
    "    wo_stop=\" \".join(wo_stop)\n",
    "    #print(wo_stop+\"\\n\\n\\n\")\n",
    "    sentences.append(wo_stop)\n",
    "for label in df.label:\n",
    "    labels.append(label)\n",
    "#print(sentences)\n",
    "print(len(sentences))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "train_ratio=0.7\n",
    "vocab_size=10000\n",
    "embedding_dim=32\n",
    "max_length=32\n",
    "trunc_type='post'\n",
    "oov_tok=\"<OOV>\"\n",
    "batch_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['title']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_tokenizer=Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "train_tokenizer.fit_on_texts(X_train)\n",
    "train_sequences=train_tokenizer.texts_to_sequences(X_train)\n",
    "train_padded=pad_sequences(train_sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "val_sequences=train_tokenizer.texts_to_sequences(X_test)\n",
    "val_padded=pad_sequences(val_sequences, maxlen=max_length, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(train_padded)\n",
    "\n",
    "X_test=np.array(val_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4489 2507]\n",
      " [ 621 5853]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.88      0.64      0.74      6996\n",
      "        True       0.70      0.90      0.79      6474\n",
      "\n",
      "    accuracy                           0.77     13470\n",
      "   macro avg       0.79      0.77      0.77     13470\n",
      "weighted avg       0.79      0.77      0.76     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
